{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GradCAM-version1.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchsummary import summary\n",
        "from PIL import Image\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import math\n",
        "from ipywidgets import interact"
      ],
      "metadata": {
        "id": "XuY9SBr8q7PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class _BaseWrapper():\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.handlers = []\n",
        "\n",
        "    def forward(self, images):\n",
        "        self.image_shape = images.shape[2:]\n",
        "        self.logits = self.model(images)\n",
        "        self.probs = F.softmax(self.logits, dim=1)\n",
        "        return self.probs.sort(dim=1, descending=True)\n",
        "\n",
        "    def backward(self, ids):\n",
        "        one_hot = F.one_hot(ids, self.logits.shape[-1])\n",
        "        one_hot = one_hot.squeeze(-2)\n",
        "        self.model.zero_grad()\n",
        "        self.logits.backward(gradient=one_hot, retain_graph=True)\n",
        "        # gradient는 해당 index에 대해서만 미분을 통한 backpropagation 진행\n",
        "        # 확인하고 싶은 class에 대해서 featuremap 영향을 확인가능\n",
        "\n",
        "    def generate(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class GradCAM(_BaseWrapper):\n",
        "    def __init__(self, model, layers=None):\n",
        "        super().__init__(model)\n",
        "        self.feature_map = {}\n",
        "        self.grad_map = {}\n",
        "        self.layers = layers\n",
        "\n",
        "        def save_fmaps(key):\n",
        "            def forward_hook(module, input, output):\n",
        "                self.feature_map[key]=output.detach()\n",
        "\n",
        "            return forward_hook\n",
        "\n",
        "        def save_grads(key):\n",
        "            def backward_hook(modeul, grad_in, grad_out):\n",
        "                self.grad_map[key] = grad_out[0].detach()\n",
        "\n",
        "            return backward_hook\n",
        "\n",
        "        for name, module in self.model.named_modules():\n",
        "            if self.layers is None or name in self.layers:\n",
        "                self.handlers.append(module.register_forward_hook(save_fmaps(name)))\n",
        "                self.handlers.append(module.register_backward_hook(save_grads(name)))\n",
        "\n",
        "    def findLayers(self, layers, target_layer):\n",
        "        if target_layer in layers.keys():\n",
        "            return layers[target_layer]\n",
        "        else:\n",
        "            raise ValueError(f\"{target_layer} not exists\")\n",
        "\n",
        "    def generate(self, target_layer):\n",
        "        feature_maps = self.findLayers(self.feature_map, target_layer)\n",
        "        print(feature_maps.size())\n",
        "        grad_maps = self.findLayers(self.grad_map, target_layer)\n",
        "        weights = F.adaptive_avg_pool2d(grad_maps, 1)\n",
        "        print(weights.size())\n",
        "        \n",
        "        grad_cam = torch.mul(feature_maps, weights).sum(dim=1, keepdim=True)\n",
        "        grad_cam = F.relu(grad_cam)\n",
        "        grad_cam = F.interpolate(grad_cam, self.image_shape, mode=\"bilinear\", align_corners=False)\n",
        "        B, C, W, H = grad_cam.shape\n",
        "\n",
        "        grad_cam = grad_cam.view(B, -1)\n",
        "        grad_cam -= grad_cam.min(dim=1, keepdim=True)[0]\n",
        "        grad_cam /= grad_cam.max(dim=1, keepdim=True)[0]\n",
        "        grad_cam = grad_cam.view(B, C, W, H)\n",
        "\n",
        "        return grad_cam"
      ],
      "metadata": {
        "id": "PZY_3qoMqa_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readImages(img_path):\n",
        "    return glob.glob(os.path.join(img_path, \"*.*\"))\n",
        "    \n",
        "\n",
        "def load_images(img_path, transform):\n",
        "    img_list = readImages(img_path)\n",
        "\n",
        "    images = []\n",
        "    raw_images = []\n",
        "    \n",
        "    for fname in img_list:\n",
        "        img = np.array(Image.open(fname))\n",
        "        img_tf = transform(img)\n",
        "        \n",
        "        images.append(img_tf)\n",
        "        raw_images.append(img)\n",
        "\n",
        "    if len(images)>1:\n",
        "        images = torch.stack(images)\n",
        "    else:\n",
        "        images = images[0].unsqueeze(0)\n",
        "\n",
        "    return images, raw_images\n",
        "\n",
        "def gradCam(model, img_path, transform=None, device=\"cuda\", target_class=0, target_layers :list =[]):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    images, raw_images = load_images(img_path, transform)\n",
        "    images = images.to(device)\n",
        "    # images는 B,C,W,H로 된 tensor, raw_images는 리스트로 된 numpy 이미지 배열\n",
        "\n",
        "    grad_cam = GradCAM(model)\n",
        "    probs, ids = grad_cam.forward(images)\n",
        "\n",
        "    target_ids = torch.LongTensor([[target_class]]*len(images)).to(device)\n",
        "\n",
        "    grad_cam.backward(target_ids)\n",
        "\n",
        "    check = []\n",
        "    # 설정한 layer가 여러개라면 모두 저장\n",
        "\n",
        "    for target_layer in target_layers:\n",
        "        print(f\"generating Grad-CAM : {target_layer}\")\n",
        "        regions = grad_cam.generate(target_layer)\n",
        "        check.append(regions)\n",
        "    \n",
        "    return check, raw_images"
      ],
      "metadata": {
        "id": "X20p3InXqyxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gauss(x,a,b,c):\n",
        "    return torch.exp(-torch.pow(torch.add(x,-b),2).div(2*c*c)).mul(a)\n",
        "\n",
        "def colorize(x):\n",
        "    if x.dim() == 2:\n",
        "        x = torch.unsqueeze(x, 0)\n",
        "    if x.dim() == 3:\n",
        "        cl = torch.zeros([3, x.size(1), x.size(2)])\n",
        "        cl[0] = gauss(x,.5,.6,.2) + gauss(x,1,.8,.3)\n",
        "        cl[1] = gauss(x,1,.5,.3)\n",
        "        cl[2] = gauss(x,1,.2,.3)\n",
        "        cl[cl.gt(1)] = 1\n",
        "    elif x.dim() == 4:\n",
        "        cl = torch.zeros([x.size(0), 3, x.size(2), x.size(3)])\n",
        "        cl[:,0,:,:] = gauss(x,.5,.6,.2) + gauss(x,1,.8,.3)\n",
        "        cl[:,1,:,:] = gauss(x,1,.5,.3)\n",
        "        cl[:,2,:,:] = gauss(x,1,.2,.3)\n",
        "    return cl"
      ],
      "metadata": {
        "id": "7fGvhcOMZWBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"모델명\"\n",
        "src_path = \"이미지가 있는 폴더명\"\n",
        "transform_ = \"이미지 transform 메소드\"\n",
        "target_layers = [\"확인하고 싶은 layer\"]\n",
        "target_class = \"확인하고 싶은 class\"\n",
        "device = \"cpu 또는 cuda\"\n",
        "\n",
        "check, original = gradCam(model, src_path, transform_, device, target_class, target_layers)\n",
        "# check (list) : 각 layer들의 feature map\n",
        "# original (list) : 이미지 "
      ],
      "metadata": {
        "id": "xtFrQ67BZ8xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 수정할 필요 X\n",
        "@interact(idx = (0, check[0].shape[0]-1))\n",
        "def showImg(idx):\n",
        "    mask = check[0][idx].squeeze().cpu().detach()\n",
        "    mask = colorize(mask)\n",
        "    H, W = mask.shape[-2], mask.shape[-1]\n",
        "\n",
        "    original_img = torch.tensor(original[idx]).permute(2, 0, 1)\n",
        "    original_img = transforms.Resize((H,W))(original_img).permute(1,2,0)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18,6))\n",
        "    fig.set_facecolor(\"black\")\n",
        "    plt.suptitle(f\"GradCAM class : {target_class}\", c=\"white\", fontsize=30, y=1.1)\n",
        "    axes[0].imshow(original_img)\n",
        "    axes[1].imshow(mask.permute(1,2,0))\n",
        "    axes[2].imshow(original_img)\n",
        "    axes[2].imshow(mask.permute(1,2,0), alpha=0.5)\n",
        "    \n",
        "    axes[0].set_title(\"original_image\", c=\"white\")\n",
        "    axes[1].set_title(f'{target_layers[0]}',c=\"white\")\n",
        "    axes[2].set_title(\"mixed_image\",c=\"white\")\n",
        "    plt.grid(False)\n",
        "    for i in range(3):\n",
        "        axes[i].set_xticks([])\n",
        "        axes[i].set_yticks([])\n",
        "    \n",
        "    for loc in [\"top\",\"bottom\",\"left\", \"right\"]:\n",
        "        for i in range(3):\n",
        "            axes[i].spines[loc].set_visible(False)\n",
        "    \n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-z2AyJ0mZbXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 예시 코드"
      ],
      "metadata": {
        "id": "6F9MCO3_aoQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "id": "V29ImdBDa1nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "src_path = \"/content/gdrive/MyDrive/test/dataset/test\"\n",
        "transform_ = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((512,512)),\n",
        "        transforms.Normalize((0.56, 0.524, 0.501), (0.258, 0.265, 0.267)),\n",
        "    ])\n",
        "target_layers = [\"layer4\"]\n",
        "target_class = 282 # imagenet 기준\n",
        "device = \"cpu\"\n",
        "\n",
        "check, original = gradCam(model, src_path, transform_, device, target_class, target_layers=[\"layer4\"])\n"
      ],
      "metadata": {
        "id": "6WIDofmRq0tB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 수정할 필요 X\n",
        "@interact(idx = (0, check[0].shape[0]-1))\n",
        "def showImg(idx):\n",
        "    mask = check[0][idx].squeeze().cpu().detach()\n",
        "    mask = colorize(mask)\n",
        "    H, W = mask.shape[-2], mask.shape[-1]\n",
        "\n",
        "    original_img = torch.tensor(original[idx]).permute(2, 0, 1)\n",
        "    original_img = transforms.Resize((H,W))(original_img).permute(1,2,0)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18,6))\n",
        "    fig.set_facecolor(\"black\")\n",
        "    plt.suptitle(f\"GradCAM class : {target_class}\", c=\"white\", fontsize=30, y=1.1)\n",
        "    axes[0].imshow(original_img)\n",
        "    axes[1].imshow(mask.permute(1,2,0))\n",
        "    axes[2].imshow(original_img)\n",
        "    axes[2].imshow(mask.permute(1,2,0), alpha=0.5)\n",
        "    \n",
        "    axes[0].set_title(\"original_image\", c=\"white\")\n",
        "    axes[1].set_title(f'{target_layers[0]}',c=\"white\")\n",
        "    axes[2].set_title(\"mixed_image\",c=\"white\")\n",
        "    plt.grid(False)\n",
        "    for i in range(3):\n",
        "        axes[i].set_xticks([])\n",
        "        axes[i].set_yticks([])\n",
        "    \n",
        "    for loc in [\"top\",\"bottom\",\"left\", \"right\"]:\n",
        "        for i in range(3):\n",
        "            axes[i].spines[loc].set_visible(False)\n",
        "    \n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ZH2go5Ftmsrw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}