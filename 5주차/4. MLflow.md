# 목차



# 1. MLflow 개요

#### 1-1. MLflow가 할 수 있는 것

- **실험 & 추적**

  - 여러 사람이 하나의 MLflow 서버 위에서 머신러닝 관련 실험을 하고 기록을 할 수 있음
  - 소스코드, 하이퍼 파라미터, Metric, 부산물 (model artifact, chart image)등 저장 가능

- **모델 Registry**

  - 머신 러닝 모델을 저장 및 등록 (자동 버전 관리)

  - 모델을 쉽게 공유 가능

- **모델 Serving**

  - 모델 registry에 등록한 모델을 REST API 형태의 서버로 Serving 가능



#### 1-2. MLflow의 구성요소

- **MLflow Tracking** : 머신러닝 코드 실행, 로깅을 위한 API, UI로 결과를 local, server에 기록해 여러 실행과 비교 가능 (다른 사용자의 결과와 비교하여 협업 가능)
- **MLflow Project** : 패키징 표준
  - 소스 코드
  - Git Repo
  - 의존성 & 실행 방법
  - MLflow tracking API 사용 시, 프로젝트 버전을 모든 파라미터와 자동으로 로깅
- **MLflow Model**
  - 모델 파일과 코드로 저장 (재현이 가능, 피클 파일 저장)
  - 다양한 플랫폼에 배포 가능한 여러 도구 제공
  - MLflow tracking API 사용 시, 해당 프로젝트에 대한 내용을 사용
- **MLflow Registry**
  - MLflow Model의 전체 lifecycle에서 사용할 수 있는 중앙 모델 저장소



# 2. MLflow 서버로 배포하기

#### 2-1. MLflow Architecture

- **파이썬 코드** 

  모델을 만들고 학습하는 코드 (mlflow run으로 실행)

- **Tracking Server**

  파이썬 코드가 실행되는 동안 Parameter, Metric, Model 등 메타 정보 저장 (파일 or DB에 저장)

- **Artifact Store**

  파이썬 코드가 실행되는 동안 생기는 Model File, Image 등의 아티팩트를 저장 (파일 or 스토리지에 저장)

#### 2-2. MLflow Tracking Server와 외부 Storage 사용하기

mlflow server 명령어로 Backend Store URI 지정