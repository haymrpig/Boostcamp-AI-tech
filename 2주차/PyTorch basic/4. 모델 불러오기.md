# Transfer learning & fine tuning

`전이학습 (transfer learning) 또는 fine tuning`: pretrained backbone을 가지고 새로운 데이터셋을 이용하여 새로운 target에 맞게 학습시키는 방법

CNN기반 ResNet, NLP에서는 transformer 기반의 bert가 자리잡으면서 전이학습이 활발하게 사용되었다. 학습 결과를 공유하고 싶다?



# 모델 저장하기

### model.save()

- 학습의 결과를 저장하기 위한 함수 

  (model architecture, parameter 저장 가능, model architecture가 더 큰 메모리를 차지)

- 모델 학습 중간 과정의 저장을 통해 최선의 결과모델을 선택 

  (early stopping 기법 등의 사용)

- 만들어진 모델을 외부 연구자와 공유하여 학습 재연성 향상

```python
for param_tensor in model.state_dict():
    print( param_tensor, "\t", model.state_dict()[param_tensor].size())
# state_dict : 모델의 파라미터를 표시

torch.save(model.state_dict(), os.path.join(MODEL_PATH, "model.pt"))
# 모델의 파라미터 저장, Ordered dict 타입
# pth는 잘 안쓰고, pt를 많이 쓴다. 

new_model = TheModelClass()
new_model.load_state_dict(torch.load(os.path.join(MODEL_PATH, "model.pt")))
# 같은 모델의 형태에서 파라미터만 load

torch.save(model, os.path.join(MODEL_PATH, "model_pickle.pt"))
# 모델의 architecture와 함께 저장, pickle방식으로 저장이 된다. 
model = torch.load(os.path.join(MODEL_PATH, "model_pickle.pt"))
# 모델의 architecture와 함께 load
```



### zipfile 다루기

```python
import zipfile

filename = "data.zip"
with zipfile.Zipfile(filename, 'r') as zip_ref:
    zip_ref.extractall()

import shutil
shutil.move('Petimages', 'data')

import os
from os import walk

mypath = "data"

f_path = []
for (dirpath, dirnames, filenames) in walk(mypath):
    f_path.extend([os.path.join(dirpath, filename) for filename in filenames])

from PIL import Image

for f_name in f_path:
    try:
        Image.open(f_name)
    except Exception as e:
        print(e)
        os.remove(f_name)

import warnings
warnings.filterwarnings("ignore")
# usr warning이 많이 뜰 때 출력안되게 함
```



# 모델의 요약정보 확인하기

### model summary

```python
from torchsummary import summary
summary(model, (3, 224, 224))
```



# 모델 학습 과정 중 최적의 결과 선택

### checkpoints

- 학습의 중간 결과를 저장하여 최선의 결과를 선택한다. 

  (earlystopping 기법 사용시 이전 학습의 결과물을 저장하여 사용가능)

- loss와 metric 값을 지속적으로 확인하고 저장

  (일반적으로 epoch, loss, metric을 함께 저장하여 확인)

```python
torch.save({
        'epoch' : e,
        'model_state_dict' : model.state_dict(),
        'optimizer_state_dict' : optimizer.state_dict(),
        'loss' : epoch_loss,
        },
f"saved/checkpoint_model_{e}_{epoch_loss/len(dataloader)}_{epoch_acc/len(dataloader)}.pt")
# 파일명이 길지만 한번에 요약이 되어있어 이런식으로 사용한다.

checkpoint = torch.load(PATH)
model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint(['optimizer_state_dict']))
epoch = checkpoint['epoch']
loss = checkpoint['loss']
```



# 전이학습

### Transfer learning

- 다른 데이터셋으로 만든 모델 (pre-trained model)을 현재 데이터에 적용
- 일반적으로 대용량 데이터셋 (ImageNet 등) 으로 만들어진 모델의 성능이 좋다. 
- 현재의 DL에서는 가장 일반적인 학습 기법
- backbone architecture가 잘 학습된 모델에서 일부만 변경해서 재사용

(CV 관련 모델 제공 - torchvision, https://github.com/rwightman/pytorch-image-models , https://github.com/qubvel/segmentation_models.pytorch)

(NLP는 HuggingFace가 사실상의 표준이다. )

```python
import torch
from torchvision import models
vgg = models.vgg16(pretrained=True).to(device)

# vgg.fc = torch.nn.Linear(1000,10)
# 이런식으로 추가할 수 있다. 

# 아니면 vgg.classifier._modules['6'] = torch.nn.Linear(4096, 1)
# 이런식으로도 가능하다. 
# vgg.classifier라는 모듈 안에 (0)번부터 (5)번까지 Linear, ReLU, Dropout 등등이 배치되어 있었고, 그 뒤에 (6)번 자리에 nn.Linear(4096,1000)이 붙어있었는데 그것을 nn.Linear(4096,1)로 변경하겠다는 의미이다.  
# for name, layer in vgg.named_modules():
#	 print( name, layer )로 확인할 수 있다. 
```



### Freezing

- pretrained model을 활용시 모델의 일부분을 frozen 시킴

  (일부 layer를 frozen시키면 그 layer에서는 back propagation이 일어나지 않음, 요즘에는 일부 layer frozen, 그 다음에는 다른 layer frozen하는 등 frozen하는 layer을 섞어가면서 학습시키고는 한다. )

```python
class MyNewNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.vgg19 = models.vgg19(pretrained=True)
        self.linear_layers = nn.Linear(1000,1)

    def forward(self, x):
        x = self.vgg19(x)
        return self.linear_layers(x)

for param in my_model.parameters():
    param.requires_grad = False
for param in my_model.linear_layers.parameters():
    param.requires_grad = True
# 마지막 layer를 제외하고 frozen시킨다. 
```

