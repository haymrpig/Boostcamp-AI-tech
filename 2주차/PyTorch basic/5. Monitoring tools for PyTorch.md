# Monitoring tools for PyTorch

현재 많이 사용하는 것은 Tensorboard와 wandb(weight&biases)



# Tensorboard

- tensorflow의 프로젝트로 만들어진 시각화 도구

  (학습 그래프, metric, 학습 결과의 시각화를 지원한다. )

- pytorch도 연결이 가능하여 DL 시각화의 핵심 도구이다. 

- 저장 가능한 요소
  - scalar : metric 등 상수 값의 연속(epoch)을 표시 ex) acc, loss 등등
  - graph : 모델의 computational graph 표시
  - histogram : weight 등 값의 분포를 표현 ( 보통 정규 분포로 표현되는 것이 좋음 )
  - image : 예측 값과 실제 값을 비교 표시
  - mesh : 3d 형태의 데이터를 표현하는 도구
  
- **예시**

```python
import os
logs_base_dir = "logs"
os.makedirs(logs_base_dir, exist_ok=True)
# tensorboard 기록을 위한 directory 생성 

from torch.utils.tensorboard import SummaryWriter
# 기록 생성 객체 SummaryWriter 생성
import numpy as np

exp  = f"{logs_base_dir}/ex3"
writer = SummaryWriter(exp)
# summary writer에 기록할 위치를 지정해준다. 
for n_iter in range(100):
    writer.add_scalar('Loss/train', np.random.random(), n_iter)
    writer.add_scalar('Loss/test', np.random.random(), n_iter)
    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)
    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)
    
# add_scalar 함수 : scalar 값을 기록
# Loss/train : loss category에 train 값을 저장
# n_iter : x축의 값

writer.flush()
# 값 기록 (disk에 쓰기)

%load_ext tensorboard
%tensorboard --logdir {logs_base_dir}
# jupyter 상에서 tensorboard 수행, 파일 위치 지정 같은 명령어를 콘솔에서도 사용가능하다. 
# 6006 port에 자동으로 생성한다. 
# 현재 log들이 log/ex3에 저장되어 있는데, 만약 log 폴더 안에 여러번의 실험 정보 ex4,ex5 등등이 있으면 모두 jupyter상에서 볼 수 있다. 
```



- **분포 보기 (weight값 조정에 많이 사용한다. )**

  ```python
  from torch.utils.tensorboard import SummaryWriter
  import numpy as np
  writer = SummaryWriter(logs_base_dir)
  for i in range(10):
      x = np.random.random(1000)
      writer.add_histogram('distribution centers', x + i, i)
  writer.close()
  ```

- **이미지 넣기**

  ```python
  from torch.utils.tensorboard import SummaryWriter
  import numpy as np
  
  img_batch = np.zeros((16, 3, 100, 100))
  for i in range(16):
      img_batch[i, 0] = np.arange(0, 10000).reshape(100, 100) / 10000 / 16 * i
      img_batch[i, 1] = (1 - np.arange(0, 10000).reshape(100, 100) / 10000) / 16 * i
  
  writer = SummaryWriter(logs_base_dir)
  writer.add_images('my_image_batch', img_batch, 0)
  writer.close()
  ```

- **3D 이미지**

  ```python
  import torch
  from torch.utils.tensorboard import SummaryWriter
  vertices_tensor = torch.as_tensor([
      [1, 1, 1],
      [-1, -1, 1],
      [1, -1, -1],
      [-1, 1, -1],
  ], dtype=torch.float).unsqueeze(0)
  colors_tensor = torch.as_tensor([
      [255, 0, 0],
      [0, 255, 0],
      [0, 0, 255],
      [255, 0, 255],
  ], dtype=torch.int).unsqueeze(0)
  faces_tensor = torch.as_tensor([
      [0, 2, 3],
      [0, 3, 1],
      [0, 1, 2],
      [1, 3, 2],
  ], dtype=torch.int).unsqueeze(0)
  
  writer = SummaryWriter(logs_base_dir)
  writer.add_mesh('my_mesh', vertices=vertices_tensor, colors=colors_tensor, faces=faces_tensor)
  
  writer.close()
  ```

- **hyper parameter 저장**

  ```python
  from torch.utils.tensorboard import SummaryWriter
  with SummaryWriter(logs_base_dir) as w:
      for i in range(5):
          w.add_hparams({'lr': 0.1*i, 'bsize': i},
                        {'hparam/accuracy': 10*i, 'hparam/loss': 10*i})
  ```

- **add_embedding**

  현재 있는 정보를 embedding (2차원 공간이나 3차원 공간으로 표현하기 위해서 압축하는 것)

- **add_figure**

  이미지 넣어주기

- **add_pr_curve_tensorboard**

  pr 곡선을 그려준다. 



# weight & biases

- ML/DL 실험을 원활히 지원하기 위한 상용도구
- 협업, code versioning, 실험 결과 기록 등 제공 (github와 유사하다.)
- MLOps의 대표적인 툴!

```python
!pip install wandb -q
import wandb

config = {"epochs":EPOCHS, "batch_size":BATCH_SIZE, "learning_rate":LEARNING_RATE}

wandb.init(project="my-test-project", config=config, entity='hong')
# project는 wandb에서 내가 만든 프로젝트 이름이다. (github와 유사한 것 같다.)
# wandb.config.batch_size = BATCH_SIZE 이런식으로 작성해도 된다. 
# entity는 wandb 가입할 때 적는 란이 있다. 

"""
여기에는 기존 코드와 같이 학습하는 코드가 들어간다.
training 단계에서 한 epoch마다 기록하기 위해 아래 코드를 추가한다. 
"""

wandb.log({'accuracy':train_acc, 'loss':train_loss})
# 기록하는 코드로 tensorboard에서의 add_함수와 동일하다. 
```



# 질문사항

weight의 분포가 정규 분포로 표현되는 것이 좋은 이유는?

