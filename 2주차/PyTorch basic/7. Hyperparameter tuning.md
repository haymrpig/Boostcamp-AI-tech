# Hyperparameter tuning

- 성능을 향상시키는 대표적인 세가지

1. 모델 바꾸기 (모델의 경우 일반화가 많이 되어있다.)
2. 데이터 바꾸기 (데이터를 바꾸는 게 가장 효과적으로 알려져 있다.)
3. Hyperparameter tuning (생각보다 크진 않다.)



- 모델 스스로 학습하지 않는 적절한 값을 tuning (hyper parameter)

  - learning rate, 모델의 크기, optimizer 등이 있다. 

  - NAS, AutoML을 이용하여 tuning하는 방법이 있다.

    - AutoML (Automated Machine Learning)

      머신러닝의 자동화에 대한 분야이다. 하이퍼파라미터 서치가 대표적인 케이스이다. 


    - NAS (Neural Architecture Search)

      AutoML에 속해있는 개념으로 네트워크 구조를 자동으로 찾아주는 방법이다. 

  - 데이터의 양이 너무 방대하기 때문에, 일반 기업에서 하이퍼 파라미터를 일반화를 하기는 힘들다. 

    (최근에는 데이터의 양이 많아져서, 하이퍼파라미터가 예전만큼의 중요성을 가지지 않는다.)



## [대표적인 방법](https://dl.acm.org/doi/pdf/10.5555/2188385.2188395)

- **grid layout**

  하이퍼파라미터의 값을 찾을 때, 일정한 범위를 정해서 값을 자르는 방식

  ex) learning rate을 0.1, 0.01, 0.001 이런식으로 조정하는 것

  batch size를 32, 64, 128개 이런식으로 선택하는 것

- **random layout**

  랜덤하게 값을 정해서 실험하는 것

  보통 random layout으로 학습하다보면 잘 나오는 구간이 생기고, 그 구간에서 grid layout방식을 이용해서 값을 찾아낸다. 

- **BOHB **

  baysian optimization 기반의 기법들을 최근에는 많이 사용한다. (논문 읽어보자)



### [대표적인 모듈(Ray)](https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html)

- multi-node multi processing 지원 모듈

  (ML/DL의 병렬 처리를 위해 개발된 모듈, 현재는 사실상의 표준이다)

- Hyperparameter search를 위한 다양한 모듈 제공

- Ray로 hyperparameter를 tuning할 때는 training 코드를 하나의 함수로 만들어야 한다. 

  ( 병렬처리하는 코드를 보면 왜 그런지 알 수 있다. )

```python
data_dir = os.path.abspath("./data")
load_data(data_dir)

config = {
	"l1": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
	"l2": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
	"lr": tune.loguniform(1e-4, 1e-1),
	"batch_size": tune.choice([2, 4, 8, 16])
}
# config에 search space를 지정한다. 

scheduler = ASHAScheduler(
	metric="loss", mode="min", max_t=max_num_epochs, grace_period=1,
	reduction_factor=2)
# 학습 스케줄링 알고리즘을 지정한다. (잘 선택하는 것이 중요하다)
# ASHA는 중간중간 loss값이 좋지 않은 값들을 잘라낸다. 더이상 학습을 돌리지 않고 잘라낸다. 

reporter = CLIReporter(
	metric_columns=["loss", "accuracy", "training_iteration"])
# 결과 출력 양식을 지정한다. 
# CLI : command line

result = tune.run(
	partial(train_cifar, data_dir=data_dir),
	resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
	config=config, num_samples=num_samples,
	scheduler=scheduler,
	progress_reporter=reporter)
# train_cifar에 train하는 함수를 넣어줘야 한다. (train은 하나의 함수로 작성해야 한다.)
# 병렬 처리 학습을 진행한다.

best_trial = result.get_best_trial("loss", "min", "last")
# get_best_trial을 통해 가장 좋았던 값들을 가져올 수 있다. 
#best_trial.config["l1"] 이렇게 해당 값도 가져올 수 있다. 
```





## 질문하기

- 모델의 모든 layer에서 learning rate가 항상 같아야 할까?

  모두 같을 필요는 없지만, optimizer를 수정해야 하는 번거로움을 감수하면서 learning rate를 수정할 필요가 있을지는 모르겠다. 

- ray tune을 이용해 hyperparameter 탐색을 하려고 합니다. 아직 어떤 hyperparmeter도 탐색한적이 없지만 시간이 없어서 1개의 hyperparameter만 탐색할 수 있다면 어떤 hyperparameter를 선택할까?

  batch size를 조절할 것 같다. batch size는 local minima에서 빠져나올 수 있게 도움을 주는 hyper parameter이므로 성능이 잘 안나왔을 때 batch를 적절하게 조절함으로 좋은 성능을 낼 수 있을 것 같다.
