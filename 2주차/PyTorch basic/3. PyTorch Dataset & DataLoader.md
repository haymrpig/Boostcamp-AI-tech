# PyTorch Dataset & DataLoader

### 개요

AI분야에서 중요한 것은 대용량 데이터를 어떻게 잘 넣어줘야 할지에 관한 issue이다. 

PyTorch dataset API는 대용량의 데이터를 모델에 쉽게 feeding하도록 도와준다. 

- 모델에 데이터를 feed하는 순서

  1. 데이터를 모으고, preprocessing을 거친다.

  2. dataset 클래스를 상속받은 객체에서 init, len, getitem을 정의한다. 

     ( getitem은 map-style이라고 하며, 하나의 데이터를 불러올 때 어떤 방식으로 반환할지 선언해주는 것으로 보통 index를 주어 하나의 데이터씩 처리한다. )

  3. DataLoader는 배치를 만들고, shuffle을 하는 등의 처리를 통해 model에 feed한다. 



### Dataset class

데이터 입력 형태를 정의하는 클래스로, 데이터 입력 방식의 표준화를 담당한다.

( 현재 model에 넣어줄 모든 데이터를 통일하며, 해당 데이터가 어떤 데이터냐에 따라 입력 형태가 달라진다.)

`init` : 초기 데이터 생성 방법을 지정한다. ex) image 데이터는 폴더를 지정해준다.

`len` : 데이터의 전체길이를 반환한다. 

`getitem` : index, dict 타입 등으로 값을 주었을 때 반환되는 데이터의 형태는 (X,Y)로 보통 dict type으로 반환한다. 

- **유의점**

  - 데이터 형태에 따라 각 함수를 다르게 정의한다. 

  - 모든 것을 데이터 생성 시점에서 처리할 필요가 없다.

    (이미지의 tensor변환의 경우 학습에 필요한 시점에 변환한다.)

  - 데이터셋에 대해 표준화된 처리방법 제공이 필요하다.

    (Custom dataset으로 후속 연구자 또는 동료에게 많은 도움이 된다.)

  - 최근에는 HuggingFace와 같은 표준화된 라이브러리를 사용한다. 



### DataLoader class

data를 batch단위로 묶고 tensor로 변환하여 생성하는 클래스이다. 

- 학습직전 (GPU fedding전) 데이터의 변환을 책임진다. ex) toTensor

- 병렬적인 데이터 전처리 코드가 중요하지만, PyTorch에는 잘 되어있어 이 부분에 대해서는 크게 문제가 없다. 

- DataLoader를 호출하는 시점에 변환을 시작한다.

- DataLoader 인자들

  - `sampler`

    데이터를 어떻게 뽑을지 index를 지정해주는 것이다.  

  - `collate_fn`

    데이터를 처리할 때 [[Data1,Label1], [Data2,Label2], .....] 이런 형태로 묶여 나오는 경우가 있는데, 이러한 데이터를 [Data1 Data2 ...] [Label1 Label2 ...] 이런 형태로 만들어주는 것이 collate_fn의 역할이다. 

    ( 보통 Variable length (가변인자) 때 사용, batch size로 하면 글자수가 다 달라서 맨 뒤를 0으로 padding해주는 경우가 있다.(글자마다 padding해야 하는 개수가 다름) 

    이런 padding을 동일하게 맞춰주는 것을 collate_fn에 정의한다.)