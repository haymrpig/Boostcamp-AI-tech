# 1. 확률론

딥러닝은 확률론 기반의 기계학습 이론에 바탕을 두고 있으며, **손실함수**들의 작동 원리는 **데이터 공간**을 **통계적으로 해석**하여 유도한다. 

ex) 

**L2 노름** : 예측오차의 **분산**을 가장 **최소화**하는 방향으로 학습

**교차엔트로피 (cross-entropy)** :모델 예측의 **불확실성**을 **최소화**하는 방향으로 학습



- **이산확률변수 & 연속확률변수**

  데이터공간 x,y에 의해 결정되는 것이 아니라, **확률변수의 확률분포**인 D에 따라 **이산, 연속**이 **구분**된다. 

  모든 확률변수가 이산확률, 연속확률은 아니다. 다른 가능성도 있다.  



- **확률분포의 모델링**

  - **확률질량함수 (PMF, probability mass function)**

    이산 분포의 경우로, 확률변수가 가질 수 있는 **모든 경우의 수**를 고려하여 **확률**을 **더하여** 모델링한다.   
    ![image](https://user-images.githubusercontent.com/71866756/150140882-9e55f05e-5657-410e-8e55-a25fcf876771.png)  

  - **확률밀도함수 (PDF, probability density function)**

    연속 분포의 경우로, 데이터 공간에 정의된 **확률변수의 밀도** 위에서 **적분**을 통해 모델링한다.   
    ![image](https://user-images.githubusercontent.com/71866756/150140936-e9a88852-d775-4d88-a688-376e3bc42ef9.png)  
    여기서 밀도는 누적확률분포(CDF)의 변화율을 모델링하며, 확률로 해석하면 안된다.
    (CDF의 미분이 PDF이니깐, PDF는 CDF의 변화율이다.)

    

  - **결합분포 (Joint)**

    결합분포는 X,Y 등 다변수에 대해서 결합된 분포라고 생각할 수 있다. 여기서 우리는 모델링 방법에 따라서 원래 분포가 연속이라 할지라도 이산으로 해석할 수 있고, 이산이라 할지라도 연속으로 해석할 수 있다. 

    즉, 원래 분포와는 다르게 **연속->이산으로 근사, 이산->연속으로 근사**할 수 있다. 

    예를 들어, 아래 그림에서 1번째 그림은 원래는 연속확률분포이지만, X와 Y의 범위에 따라 여러 블록으로 나누고 각 블록에 대한 확률분포를 이산확률분포로써 모델링할 수 있다.

    2번째 그림은 결합분포의 X의 marginal 분포를 의미한다.   

    ![image](https://user-images.githubusercontent.com/71866756/150140988-2b51e1f3-907a-4d96-adc2-9f0e96164055.png)

    

  - **주변확률분포 (marginal distribution)**

    결합분포에서 특정 확률변수에 대한 분포를 보고 싶을 때 사용한다.

    만약 X에 대한 marginal distribution을 구하면 **Y에 대한 정보를 주지 않기** 때문에, 

    일반적으로 **조건부확률분포를 사용하여 모델링(x와 y사이 관계)**을 한다.

      

  - **조건부확률**  
    ![image](https://user-images.githubusercontent.com/71866756/150141049-f5ca5fb5-31d2-45de-a0ab-4aaaf42f7907.png)  
    분류 문제에서 **softmax**는 x로부터 추출된 특징패턴과 가중치행렬을 통해 **조건부확률**을 **계산**한다.   
    ![image](https://user-images.githubusercontent.com/71866756/150141105-9b975659-895c-4ec8-9f7d-92cd10e71606.png)  
    **회귀 문제**의 경우(연속확률이 대부분) **조건부 기대값**을 추정한다.   
    ![image](https://user-images.githubusercontent.com/71866756/150141153-36aaff1b-390a-49f5-9490-270894f69707.png)  
    회귀문제에서 조건부 기대값을 사용하는 이유는 L2노름을 최소화하는 함수는 조건부 기대값의 함수와 일치하기 때문이다. (수학적으로 증명되어 있음)

    

  - **기대값**

    **확률분포**가 주어지면 데이터를 분석하는데 사용 가능한 여러 종류의 **통계적 범함수**(statistical functional)을 계산할 수 있으며, 기대값은 **데이터를 대표하는 통계량**이며 동시에 확률분포를 통해 다른 **통계적 범함수를 계산**하는데 사용된다.   
    ![image](https://user-images.githubusercontent.com/71866756/150141202-34d655c7-8945-4a48-9fbc-6dcfd355a5c0.png)  
    기대값으로 구할 수 있는 통계량으로는 **분산, 첨도, 공분산** 등이 있다.   
    ![image](https://user-images.githubusercontent.com/71866756/150141249-7811ab8a-145b-4a8f-8ae1-944ab613a738.png)  

  - **몬테카를로 샘플링 (Monte Carlo sampling)**

    보통 많은 문제들의 경우 확률분포를 명시적으로 모를 때가 대부분이다. 

    확률분포를 모를 때, 데이터를 이용하여 **기대값**을 **계산**하려면 **몬테카를로 (Monte Carlo) 샘플링** 방법을 이용한다. 

    (**이산, 연속 상관없이 성립**)  
    ![image](https://user-images.githubusercontent.com/71866756/150141287-a1a06ccf-d6e0-49cb-9c1a-a49d9fa9893c.png)  
    몬테카를로 샘플링은 **독립추출**만 보장된다면 **대수의 법칙(law of large number)에 의해** **수렴**성을 보장한다. 

    EX)

    ![image](https://user-images.githubusercontent.com/71866756/150141333-63378756-673e-4af8-ac1e-03f6e3cb6a2e.png)  
    

    위 식은 부정적분으로는 구할 수 없기 때문에 몬테카를로 샘플링을 이용한다. 

    먼저, 데이터를 Unif(-1,1)로 균등하게 샘플링한다고 하면, 확률분포로 바꿔주기 위해서는 2로 나눠줘야 한다. (확률분포의 정의에 따라)

    따라서  
    ![image](https://user-images.githubusercontent.com/71866756/150141386-5e44ab81-48d9-452f-b206-bfd1f1ff710d.png)  
    이 된다. 

    몬테카를로 샘플링에서는 적절한 샘플의 양을 조절하는 것이 중요하다. 
