# 목차

1. [**벡터**](#1-벡터)
   - 정의
   - 벡터의 종류
   - 벡터의 연산
   - 노름
   - 내적
2. [**행렬**](#2-행렬)
   - 정의
   - 종류
   - 연산

# 1. 벡터

- **정의**

  벡터는 숫자를 원소로 가지는 리스트(list) 또는 배열(array)이며, 공간에서 **원점으로부터 상대적 위치**의 한점을 나타낸다. 

- **벡터의 종류**

  - 열벡터  

  ![image](https://user-images.githubusercontent.com/71866756/149742429-c0f640dd-e692-499e-978d-4a64d6833865.png)  


  - 행벡터  
    ![image](https://user-images.githubusercontent.com/71866756/149742497-a214c15d-1945-4d5b-82fc-c4af7f13ccb9.png)  

- **벡터의 연산**

  - 스칼라곱

    벡터에 숫자를 곱하면 길이가 변한다.   
    ![image](https://user-images.githubusercontent.com/71866756/149742557-637ec3ba-94f8-4810-8614-81dab90a9377.png)  

   

  - 덧셈 / 뺄셈

    두 벡터의 덧셈 / 뺄셈은 다른 벡터로부터의 **상대적 위치이동**이다.   
    ![image](https://user-images.githubusercontent.com/71866756/149742627-c95d4e88-0459-48b4-ad8f-2c0625df318c.png)  
    

  - 성분곱 (Hadamard product)  
    ![image](https://user-images.githubusercontent.com/71866756/149742703-9efc8837-6aaf-4687-8c01-5f25c3ac4a81.png)  
    

- **노름**

  원점에서의 거리를 의미한다. ( 차원에 상관없이 정의 가능 )

  노름의 종류에 따라 **기하학적 성질**이 달라지며, L1 노름의 경우 마름모꼴, L2 노름의 경우 원형인 것을 알 수 있다.  ( 학습 진행 시 정규화, 최적화에 이용 )

  L1의 경우, robust하게 학습을 할 때, L2는 라플라스 분사 등에 사용된다. 

  - L1 노름  
    ![image](https://user-images.githubusercontent.com/71866756/149742818-5585b3f9-5c0a-4d25-9b90-1d75080fb92d.png)  

    ```python
    # code
    x_norm1 = np.abs(x)
    x_norm1 = np.sum(x_norm)
    ```

    

    

  - L2 노름  
    ![image](https://user-images.githubusercontent.com/71866756/149742870-34e064da-1e0c-4e04-9aa5-6cdf27872511.png)  

    ```python
    # code
    x_norm2 = x*x
    x_norm2 = np.sum(x_norm2)
    x_norm2 = np.sqrt(x_norm2)
    ```

    

  - L1, L2를 이용한 두 벡터 사이 거리 계산 

    두 벡터의 거리는 벡터의 뺄셈을 이용한다.   
    ![image](https://user-images.githubusercontent.com/71866756/149742926-f2838fa5-7854-4d18-af98-b2b2260ba8ec.png)  

  - 두 벡터 사이각

    두 벡터의 사이각은 **L2 노름**만 가능하다. **제 2 코사인 법칙**을 이용한다.   
    ![image](https://user-images.githubusercontent.com/71866756/149742969-a9f6a7ad-8857-4d90-95fc-e8b7d38d3806.png)  

    ```python
    # code
    v1 = np.inner(x,y) / (L2_norm(x)*L2_norm(y))
    theta = np.arccos(v1)
    ```

  

- **내적**

  정사영된 벡터의 길이는 코사인 법칙에 의해 아래 식이 되고, 내적은 **정사영된 벡터**의 길이를 벡터 y의 길이만큼 조정한 값이라고 할 수 있다. 

  즉, **두 벡터의 유사도**를 의미한다.   
  ![image](https://user-images.githubusercontent.com/71866756/149743014-7f78b947-7f9a-4e04-939b-7c4a6911e17e.png)  



# 2. 행렬

- **정의**

  벡터를 원소로 가지는 **2차원 배열**을 의미한다. (numpy에서는 행이 기본 단위로, 행벡터를 원소로 가진다고 할 수 있다.)

  벡터가 공간에서의 한 점을 의미하면, 행렬은 공간에서 여러 점들을 의미한다. 

- **종류**

  - 전치행렬 (transpose matrix)  
    ![image](https://user-images.githubusercontent.com/71866756/149743086-009a6fff-5153-4c3d-a106-86759ec084aa.png)  

  - 역행렬 (inverse matrix)

    어떤 행렬 A와 곱했을 때, 항등 행렬이 나오는 행렬을 의미한다. 정방행렬이며, 행렬식 (determinant)가 0이 아닌 경우에만 계산할 수 있다.   
    ![image](https://user-images.githubusercontent.com/71866756/149743136-c1f7036c-c79d-4973-b807-a155ef8b2666.png)  

    ```python
    # code
    np.linalg.inv(x)
    ```

  - 유사역행렬 (pseudo-inverse) 또는 무어펜로즈 역행렬 (Moore-Penrose)

    역행렬을 계산할 수 없는 경우 유사역행렬을 통해 역행렬을 구한다. (아래 식)

    선형모델에선 n이 데이터의 개수, m이 데이터 feature개수라고 생각할 수 있고, 유사역행렬을 이용하여 선형회귀식을 구할 수 있다.   
    ![image](https://user-images.githubusercontent.com/71866756/149743188-1c7f8832-08f8-4fea-af2d-e9790ea38b3d.png)  

    ```python
    # code
    np.linalg.pinv(x)
    
    # 라이브러리를 활용한 회귀분석 
    from sklearn.linear_model import LinearRegression
    model = LinearRegression()
    model.fit(x,y)
    y_test = model.predict(x_test)
    
    # Moore-Penrose 역행렬을 이용한 회귀분석
    X_ = np.array([np.append(x,[1]) for x in X])
    beta = np.linalg.pinv(X_) @ y
    y_test = np.append(x,[1]) @ beta
    
    # 두 결과가 다른 이유는 Moore-Penrose의 경우 y절편을 직접 추가하기 때문이다. 
    ```

    

- **연산**

  같은 모양을 가질 경우, 연산이 가능하다. 

  - 덧셈 / 뺄셈  
    ![image](https://user-images.githubusercontent.com/71866756/149743250-446a85e4-b60c-4cd0-aa5d-a364c6764333.png)  

  - 성분곱  
    ![image](https://user-images.githubusercontent.com/71866756/150666393-6413b818-679e-43b6-be6b-1f91b34dbfed.png)
  

  - 스칼라곱  
    ![image](https://user-images.githubusercontent.com/71866756/149743358-a023ee71-a974-4999-a846-4620115198ab.png)  

  - 행렬 곱셈 (matrix multiplication)

    행렬곱을 통해 벡터를 **다른 차원의 공간**으로 보내는 것으로 이해할 수 있다. 

    즉, 주어진 데이터에서 패턴을 추출, 데이터를 압축할 수도 있다. 

    모든 선형변환 (Linear transform)은 행렬곱으로 표현할 수 있다.   
    ![image](https://user-images.githubusercontent.com/71866756/149743425-10e00544-05eb-434f-87b0-794b8741839e.png)  
    

    i번째 행벡터와 j번째 열벡터 사이의 내적으로 계산한다. 

    (X의 열, Y의 행 개수가 같아야 한다.)  
    ![image](https://user-images.githubusercontent.com/71866756/149743473-6edbbdc5-321b-4c02-b6eb-31f9f6fc265b.png)  

    ```python
    # code
    X@Y
    # np.inner의 경우는 i번째 행벡터와 j번째 행벡터 사이의 내적을 의미한다. (수학에서의 내적과는 다르다!)
    ```

  

  
